---
title: "一个高性能分布式 CMDB 平台的设计"
date: 2022-09-07T00:25:20+08:00
draft: true
categories: ["article"]
length: 0
description: "[迁移]面向云原生的 CMDB 平台的设计思路。"
---

任何一个 CMDB 都不值得开源，因为每个公司都不一样。

因为成本问题，公司管理层决定替换掉 [ManageEngine](https://www.manageengine.com/) 的 ServiceDesk Plus 服务。这是第一次自己设计的运维平台系统允许被通过外部文章的方式发布出来。这篇文章介绍了针对 Web 业务类型的公司如何从零构建一个 CMDB 系统。笔者所在的公司有相当一部分裸金属服务，还有一个阿里云的 ECS 云虚拟机，我们在云虚拟机上部署了 Kubernetes 集群。

由于笔者的公司主要深耕在线教育行业，视频和文章是必须的。我们通过 ffmpeg、h264、h265 程序对原始数据进行压制。通过对象存储实现我们的视频、音频和图片内容的存储。一些评论通过 MongoDB 存储。我们有很多学员在海外，全球网络延时也是很大的阻碍因素。接下来我们将讨论如何避免这样的问题。

# 架构图

笔者所在公司的研发部门使用 Java 构建业务应用，我们运维部门决定采用 Go 语言和 Vue.js 构建我们的运维系统。话不多说，先上架构图：

![](/article/a-fast-distributed-cmdb-design/arch.svg)

先放一句大话：此架构适用于任何规模的公司！

# 现有集群的复用

- **分布式配置数据存储**：由于笔者所在的公司全部使用 MongoDB，那么我们运维部门也考虑采用 MongoDB，毕竟有先前的经验积累，另外可以复用现有的 MongoDB 集群。
- **分布式协调**：此外我们还复用了现有的分布式协调集群 ———— Zookeeper，不过这个运维平台从代码上兼容了 ZooKeeper 和 ETCD，通过配置文件的驱动字段可以修改。
- **分布式消息系统**：业务部门使用了 Kafka 作为消息中间件，另外我们还使用了 ELK 作为在线日志系统供研发部门查询，所以消息集群仍旧是 Kafka。

# 运维业务元数据

运维平台从元数据管理和配置管理进行了设计，元数据包括端口、IP地址、服务等。运维同学可以新建一些元数据，然后对这些元数据进行操作。这就很简单了，无非就是对一些 Document 的增删改查，由于笔者之前在某游戏公司工作，这个想法参考了某游戏公司的实现。

笔者是个喜欢创新的人，我们通过元数据实现了业务全景图，这样在可视化场景为运维人员提供业务拓扑、业务树、网络拓扑等组织管理形式，方便运维人员对整个业务系统运行状态和部署架构全局一览，清晰便捷。

# 前后端分离

笔者和其他的小伙伴使用了 Vue.js、ECharts 和 Naive UI 构建了 CMDB 的前端，通过 json-rpc 向后端发送请求。

我们通过 GitLab 存储工程代码，这样可以使用 Actions 在推送到 release 分支的时候自动编译生成到 NFS 服务的某个目录，然后 NGINX 对这个目录进行读取。

由于运维平台只有公司内部使用，我们通过 Certbot 部署和自动订阅 SSL 功能。

前端通过 json-rpc 向后端发送请求，我们根据最新的 RFC 文档为 JavaScript 构建了 json-rpc 库。Go 的标准库中本来就有一个 json-rpc 的支持，所以可以直接拿来用。笔者特别喜欢 json-rpc，这还是在看区块链框架源码的时候知道的这个库。相比于 gRPC，json-rpc 通过人类易读的方式传送数据，并且是前端支持的，不需要任何代理。gRPC 通常通过 Enovy 进行代理，增加了部署的难度。

RESTful API 这种设计并不适合复杂的应用，你会将大量的心智用于设计 API 而不是快速实现业务。json-rpc 的请求到达 NGINX 后仍旧使用文本的方式被反向代理并且进行 HTTPS 脱壳为 HTTP 发送到 API Server。

# API Server 与定时任务

API Server 接收来自前端的请求，并且被设计为无状态的普通 Web API 服务。可以通过无限的水平扩展实现更高的负载。

当一个元数据处理请求到达 API Server 时，API Server 会对 MongoDB 进行一系列操作完成请求负载。

当一个新的配置变更请求到达 API Server 时，API Server 会直接将请求写入到 MongoDB。由 Message Job 和 Watch Job 对相关的数据进行轮询监控。

Watch Job 发现数据有变更时，通过读取数据并向 MQ 投递消息。这样订阅某个主题的客户端就可更新配置了。由于笔者使用 MongoDB 作为配置存储，那么可以通过 Change Stream 的方式订阅 MongoDB 中的数据变更。

Message Job 主要实现了 WebHook 与邮件通知功能，笔者的公司使用钉钉作为主要的通讯工具，邮件只是重要消息的存档备份。通常，运维人员需要向 Message Job 提供一个 URL 和 Signature Key。

因为 Job 具有各种状态并且处理各种状态，所以我们将 Job 设计为多副本的服务。Job 连接到 Zookeeper 或者 ETCD 实现分布式协调。

# WebSocket Gateway 实现实时更新

配置由 API Server 创建，然后接着被 Watch Job 发现后投递到 MQ，然后再由订阅了相关主题的 Agent 去消费更新，这无疑只能实现秒级的配置更新，笔者的系统空闲状态下，一个新配置的下发需要8秒。

笔者设计了一个实时生效的配置更新方案，那就是使用 WebSocket 和 SDK 相结合。这是在系统上下一段时间后研发部门提出的需求。

API Server 接收了处理请求后在 MongoDB 中进行相关记录后直接投递消息到 MQ。
WebSocket Gateway 按照自己的消费速率从 MQ 中读取。由于客户端使用了 SDK，业务应用在启动后会直接与 WebSocket Gateway 建立 WebSocket 连接，新配置是推送的，而不是被动等待。
笔者的系统空闲状态下，一个新配置使用 WebSocket 下发在1秒之内，海外节点在2秒之内。

# Agent 

Agent 被设计为一个守护进程，通过配置文件托管某些行为，例如要 Watch 哪些配置文件，当取到消息时更新。

# 自托管

API Server、各种 Job、WebSocket Gateway 都是服务，它们的运行也离不开配置。幸运的是，这些配置会被笔者所开发的系统托管。

自研的运维平台能够很方便的接入到公司内部的流程审核系统，在这里就不多赘述了，毕竟每个公司都不一样。

# 在未来

Ansible 是企业中常用的自动化工具，通过将此平台与 Ansible 进行融合，还能实现以 DSL 的方式修改配置。
ini、conf 文件虽然是现在的主流，但是 ts、js、py、lua 才是未来配置文件格式的主流。
毕竟一切都开始了 DSL 化。