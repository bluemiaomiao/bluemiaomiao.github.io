<!doctype html><html lang=zh><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Halo的主页 - 使用 DCGM 监控 Kubernetes 中的 NVIDIA GPU</title><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@500&display=swap" rel=stylesheet><link rel=stylesheet href=../../css/halo.css><link rel=stylesheet href=../../css/github-markdown.css><link rel=stylesheet href=../../css/github-markdown-light.css><link rel=stylesheet href=../../css/markdown-rewrite.css><link rel="shortcut icon" href=favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#ffffff"><meta name=theme-color content="#ffffff"><style>body{display:flex;flex-direction:column;align-items:center}a{color:#5e5e5e;text-decoration:none}</style></head><body><div id=mob-warning>当前内容暂不适配移动端。<br>请使用桌面端查看。</div><div id=top style=width:0;height:0></div><div class=top-button><a href=#top style=text-decoration:none>Top</a></div><div id=toc>目<br>录</div><div id=header><div style=width:100%;display:flex;align-items:center;height:100%><div class=disable-select style=display:flex;justify-content:flex-end;font-size:14pt;font-weight:700;color:#555><div style=margin-right:35px></div><div><a style=color:#555;text-decoration:none href=../../>&lt;Halo的主页/></a></div></div><div style=flex:1;display:flex;justify-content:flex-end;font-size:14pt;font-weight:700;color:#555><div style=margin-right:45px><a href=../../article style=color:#555;text-decoration:none>文章</a></div><div style=margin-right:45px><a href=../../video style=color:#555;text-decoration:none>视频</a></div><div style=margin-right:45px><a href=../../about style=color:#555;text-decoration:none>关于</a></div><div style=margin-left:35px></div></div></div></div><div id=article-content><div class=content-header><div>《使用 DCGM 监控 Kubernetes 中的 NVIDIA GPU》</div><div style=font-size:10pt;height:100%;display:flex;align-items:flex-end;padding-bottom:12pt;color:#5e5e5e;font-weight:lighter>在2023/07/17 00:22:04更新，大约共700字。</div></div><div class=content-desc><div style=font-size:50pt;font-weight:700;color:#eee;padding-right:15px>“</div><div style=line-height:50pt;color:#9b9b9b>了解 NVIDIA DCGM 架构，并部署使用</div><div style=font-size:50pt;font-weight:700;color:#eee;padding-left:15px>”</div></div><div class="content-area markdown-body"><p>从数据中心和云到桌面和边缘，NVIDIA Cloud Native 技术提供了在配备 NVIDIA GPU 的系统上运行深度学习、机器学习和由 Kubernetes 管理的其他 GPU 加速工作负载的能力，并开发可用于无缝部署在企业云原生管理框架上。NVIDIA 积极的拥抱了 Kubernetes，并且提供了深度的集成：</p><p><img src=../../article/monitoring-gpus-in-kubernetes-with-dcgm/egx-cloud-native-core-stack-850x480-2x.jpg alt></p><p>对于管理 AI 或 HPC 工作负载的大规模 GPU 集群的基础设施或站点可靠性工程 (SRE) 团队来说，监控 GPU 至关重要。GPU 指标使团队能够了解工作负载行为，从而优化资源分配和利用率、诊断异常并提高数据中心的整体效率。除了基础设施团队之外，无论您是从事 GPU 加速的 ML 工作流程的研究人员，还是喜欢了解容量规划的 GPU 利用率和饱和度的数据中心设计人员，您可能也对指标感兴趣。</p><p>随着 AI/ML 工作负载使用 Kubernetes 等容器管理平台进行容器化和扩展，这些趋势变得更加重要。在这篇文章中，我们概述了 NVIDIA 数据中心 GPU 管理器 (DCGM)，以及如何将其集成到 Prometheus 和 Grafana 等开源工具中，以形成 Kubernetes GPU 监控解决方案的构建块。</p><h1 id=nvidia-dcgm>NVIDIA DCGM</h1><p>NVIDIA 数据中心 GPU 管理器 (DCGM) 是一套用于在集群环境中管理和监控 NVIDIA 数据中心 GPU 的工具。它包括主动健康监控、全面诊断、系统警报和治理策略（包括电源和时钟管理）。它可以由基础设施团队独立使用，也可以轻松集成到 NVIDIA 合作伙伴的集群管理工具、资源调度和监控产品中。</p><p>DCGM 简化了数据中心的 GPU 管理，提高了资源可靠性和正常运行时间，自动执行管理任务，并帮助提高整体基础设施效率。DCGM 支持 x86_64、Arm 和 POWER (ppc64le) 平台上的 Linux 操作系统。安装程序包包括库、二进制文件、NVIDIA 验证套件 (NVVS) 以及使用 API（C、Python 和 Go）的源示例。DCGM 还使用 DCGM Exporter 集成到 Kubernetes 生态系统中，以在容器化环境中提供丰富的 GPU 遥测。</p><p>存储库在这里：<a href=https://github.com/NVIDIA/DCGM>https://github.com/NVIDIA/DCGM</a>，文档在这里：<a href=https://docs.nvidia.com/datacenter/dcgm/latest/>https://docs.nvidia.com/datacenter/dcgm/latest/</a>，笔者在 Ubuntu Server 上安装：</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
</span></span><span style=display:flex><span>sudo dpkg -i cuda-keyring_1.0-1_all.deb
</span></span><span style=display:flex><span>sudo add-apt-repository <span style=color:#5af78e>&#34;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sudo apt-get update
</span></span><span style=display:flex><span>sudo apt-get install -y datacenter-gpu-manager
</span></span><span style=display:flex><span>sudo systemctl --now <span style=color:#ff5c57>enable</span> nvidia-dcgm
</span></span><span style=display:flex><span>dcgmi discovery -l <span style=color:#78787e># 您应该会看到系统中找到的所有支持的 GPU（以及任何 NVSwitch）的列表</span>
</span></span></code></pre></td></tr></table></div></div><p>DCGM 应该在虚拟机或者物理机上安装，而不是容器环境。</p><h1 id=nvidia-dcgm-指标导出器>NVIDIA DCGM 指标导出器</h1><p>监控堆栈通常由收集器、用于存储指标的时间序列数据库和可视化层组成。Prometheus是一个流行的开源堆栈，它与Grafana一起用作可视化工具来创建丰富的仪表板。Prometheus 还包括Alertmanager来创建和管理警报。Prometheus 与kube-state-metrics和node_exporter一起部署，以公开 Kubernetes API 对象的集群级指标和节点级指标（例如 CPU 利用率）。</p><p>在前面描述的 Go API 的基础上，您可以使用 DCGM 将 GPU 指标公开给 Prometheus。dcgm-exporter 使用 Go 绑定从 DCGM 收集 GPU 遥测数据，然后公开 Prometheus 使用 HTTP 端点 (<code>/metrics</code>) 提取的指标。dcgm-exporter 也是可配置的。您可以使用 <code>.csv</code> 格式的输入配置文件自定义 DCGM 收集的 GPU 指标。</p><h1 id=kubernetes-集群中每个-pod-的-gpu-指标>Kubernetes 集群中每个 Pod 的 GPU 指标</h1><p>dcgm-exporter 收集节点上所有可用 GPU 的指标。然而，在 Kubernetes 中，您可能不一定知道当 Pod 请求 GPU 资源时，节点中的哪些 GPU 会被分配给 Pod。从 v1.13 开始，kubelet添加了设备监控功能，可让您使用 pod-resources 套接字查找分配给 Pod 的设备（Pod名称、Pod 命名空间和设备 ID）。dcgm-exporter 中的 HTTP 服务器连接到kubelet 的 Pod 资源服务器 (<code>/var/lib/kubelet/pod-resources</code>) 以识别 Pod 上运行的 GPU 设备，并将 GPU 设备 Pod 信息附加到收集的指标中。</p><h1 id=设置-gpu-监控解决方案>设置 GPU 监控解决方案</h1><p>以下是一些 dcgm-exporter 设置示例 。如果您使用 NVIDIA GPU Operator，则 dcgm-exporter 是作为该 Operator 的一部分部署的组件之一。我们现在在一个已经就绪的 Kubernetes 集群中安装 Prometheus：</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
</span></span><span style=display:flex><span>helm repo update
</span></span><span style=display:flex><span>helm inspect values prometheus-community/kube-prometheus-stack &gt; /tmp/kube-prometheus-stack.values
</span></span><span style=display:flex><span>helm install prometheus-community/kube-prometheus-stack --create-namespace --namespace prometheus --generate-name --set prometheus.service.type<span style=color:#ff6ac1>=</span>NodePort --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues<span style=color:#ff6ac1>=</span><span style=color:#ff5c57>false</span>
</span></span><span style=display:flex><span>kubectl get pods -A
</span></span><span style=display:flex><span>kubectl get svc -A
</span></span></code></pre></td></tr></table></div></div><p>然后安装 dcgm-exporter：</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>helm repo add gpu-helm-charts https://nvidia.github.io/gpu-monitoring-tools/helm-charts
</span></span><span style=display:flex><span>helm repo update
</span></span><span style=display:flex><span>helm install --generate-name gpu-helm-charts/dcgm-exporter
</span></span><span style=display:flex><span>helm ls
</span></span><span style=display:flex><span>kubectl get svc -A
</span></span></code></pre></td></tr></table></div></div><p>使用暴露在32032端口的Grafana服务，访问Grafana主页。使用 Prometheus 图表中提供的凭据登录仪表板：<code>adminPassword</code> 中的字段 <code>prometheus.values</code>。现在要启动用于 GPU 指标的 Grafana 仪表板，请从Grafana Dashboards导入参考 NVIDIA 仪表板，具体的内容在这里：<a href=https://grafana.com/grafana/dashboards/12239-nvidia-dcgm-exporter-dashboard/>https://grafana.com/grafana/dashboards/12239-nvidia-dcgm-exporter-dashboard/</a>。</p><p><img src=../../article/monitoring-gpus-in-kubernetes-with-dcgm/nvidia-dcgm-exporter-dashboard.png alt></p><p>现在运行一些GPU工作负载。为此，DCGM包括一个名为 dcgmproftester 的CUDA负载生成器。它可用于生成确定性CUDA工作负载，用于读取和验证GPU度量。我们有一个容器化的dcgmproftester，您可以使用它，在Docker命令行上运行。此示例生成半精度（FP16）矩阵乘法（GEMM）并使用GPU上的张量核。要生成负载，您必须首先下载DCGM并将其容器化。以下脚本创建了一个可用于运行dcgmproftester的容器。此容器可在NVIDIA DockerHub存储库中找到。</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#78787e>#!/usr/bin/env bash
</span></span></span><span style=display:flex><span><span style=color:#78787e></span><span style=color:#ff5c57>set</span> -exo pipefail
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>mkdir -p /tmp/dcgm-docker
</span></span><span style=display:flex><span><span style=color:#ff5c57>pushd</span> /tmp/dcgm-docker
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>cat &gt; Dockerfile <span style=color:#5af78e>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#5af78e>ARG BASE_DIST
</span></span></span><span style=display:flex><span><span style=color:#5af78e>ARG CUDA_VER
</span></span></span><span style=display:flex><span><span style=color:#5af78e>FROM nvidia/cuda:\${CUDA_VER}-base-\${BASE_DIST}
</span></span></span><span style=display:flex><span><span style=color:#5af78e>LABEL io.k8s.display-name=&#34;NVIDIA dcgmproftester&#34;
</span></span></span><span style=display:flex><span><span style=color:#5af78e> 
</span></span></span><span style=display:flex><span><span style=color:#5af78e>ARG DCGM_VERSION
</span></span></span><span style=display:flex><span><span style=color:#5af78e> 
</span></span></span><span style=display:flex><span><span style=color:#5af78e>WORKDIR /dcgm
</span></span></span><span style=display:flex><span><span style=color:#5af78e>RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    libgomp1 \
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    wget &amp;&amp; \
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    rm -rf /var/lib/apt/lists/* &amp;&amp; \
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    wget --no-check-certificate https://developer.download.nvidia.com/compute/redist/dcgm/\${DCGM_VERSION}/DEBS/datacenter-gpu-manager_\${DCGM_VERSION}_amd64.deb &amp;&amp; \
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    dpkg -i datacenter-gpu-manager_*.deb &amp;&amp; \
</span></span></span><span style=display:flex><span><span style=color:#5af78e>    rm -f datacenter-gpu-manager_*.deb
</span></span></span><span style=display:flex><span><span style=color:#5af78e> 
</span></span></span><span style=display:flex><span><span style=color:#5af78e>ENTRYPOINT [&#34;/usr/bin/dcgmproftester11&#34;]
</span></span></span><span style=display:flex><span><span style=color:#5af78e>EOF</span>
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span><span style=color:#ff5c57>DIR</span><span style=color:#ff6ac1>=</span>.
</span></span><span style=display:flex><span><span style=color:#ff5c57>DCGM_REL_VERSION</span><span style=color:#ff6ac1>=</span>2.0.10
</span></span><span style=display:flex><span><span style=color:#ff5c57>BASE_DIST</span><span style=color:#ff6ac1>=</span>ubuntu18.04
</span></span><span style=display:flex><span><span style=color:#ff5c57>CUDA_VER</span><span style=color:#ff6ac1>=</span>11.0
</span></span><span style=display:flex><span><span style=color:#ff5c57>IMAGE_NAME</span><span style=color:#ff6ac1>=</span>nvidia/samples:dcgmproftester-<span style=color:#ff5c57>$DCGM_REL_VERSION</span>-cuda<span style=color:#ff5c57>$CUDA_VER</span>-<span style=color:#ff5c57>$BASE_DIST</span>
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>docker build --pull <span style=color:#5af78e>\
</span></span></span><span style=display:flex><span><span style=color:#5af78e></span>        -t <span style=color:#5af78e>&#34;</span><span style=color:#ff5c57>$IMAGE_NAME</span><span style=color:#5af78e>&#34;</span> <span style=color:#5af78e>\
</span></span></span><span style=display:flex><span><span style=color:#5af78e></span>        --build-arg <span style=color:#ff5c57>DCGM_VERSION</span><span style=color:#ff6ac1>=</span><span style=color:#ff5c57>$DCGM_REL_VERSION</span> <span style=color:#5af78e>\
</span></span></span><span style=display:flex><span><span style=color:#5af78e></span>        --build-arg <span style=color:#ff5c57>BASE_DIST</span><span style=color:#ff6ac1>=</span><span style=color:#ff5c57>$BASE_DIST</span> <span style=color:#5af78e>\
</span></span></span><span style=display:flex><span><span style=color:#5af78e></span>        --build-arg <span style=color:#ff5c57>CUDA_VER</span><span style=color:#ff6ac1>=</span><span style=color:#ff5c57>$CUDA_VER</span> <span style=color:#5af78e>\
</span></span></span><span style=display:flex><span><span style=color:#5af78e></span>        --file Dockerfile <span style=color:#5af78e>\
</span></span></span><span style=display:flex><span><span style=color:#5af78e></span>        <span style=color:#5af78e>&#34;</span><span style=color:#ff5c57>$DIR</span><span style=color:#5af78e>&#34;</span> <span style=color:#ff5c57>popd</span>
</span></span></code></pre></td></tr></table></div></div><p>在Kubernetes集群上部署容器之前，请尝试在Docker中运行它。在本例中，通过指定-t 1004，使用张量核心触发FP16矩阵乘法，并运行测试-d 45（45秒）。您可以通过修改-t参数来尝试运行其他工作负载。</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>docker run --rm --gpus all --cap-add<span style=color:#ff6ac1>=</span>SYS_ADMIN nvidia/samples:dcgmproftester-2.0.10-cuda11.0-ubuntu18.04 --no-dcgm-validation -t <span style=color:#ff9f43>1004</span> -d <span style=color:#ff9f43>45</span>
</span></span></code></pre></td></tr></table></div></div><p>将其安排到您的Kubernetes集群中，并在Grafana仪表板中查看相应的指标。以下代码示例使用容器的适当参数构造了这个podspec：</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>cat <span style=color:#5af78e>&lt;&lt; EOF | kubectl create -f -
</span></span></span><span style=display:flex><span><span style=color:#5af78e> apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#5af78e> kind: Pod
</span></span></span><span style=display:flex><span><span style=color:#5af78e> metadata:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>   name: dcgmproftester
</span></span></span><span style=display:flex><span><span style=color:#5af78e> spec:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>   restartPolicy: OnFailure
</span></span></span><span style=display:flex><span><span style=color:#5af78e>   containers:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>   - name: dcgmproftester11
</span></span></span><span style=display:flex><span><span style=color:#5af78e>     image: nvidia/samples:dcgmproftester-2.0.10-cuda11.0-ubuntu18.04
</span></span></span><span style=display:flex><span><span style=color:#5af78e>     args: [&#34;--no-dcgm-validation&#34;, &#34;-t 1004&#34;, &#34;-d 120&#34;]
</span></span></span><span style=display:flex><span><span style=color:#5af78e>     resources:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>       limits:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>          nvidia.com/gpu: 1
</span></span></span><span style=display:flex><span><span style=color:#5af78e>     securityContext:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>       capabilities:
</span></span></span><span style=display:flex><span><span style=color:#5af78e>          add: [&#34;SYS_ADMIN&#34;]
</span></span></span><span style=display:flex><span><span style=color:#5af78e> 
</span></span></span><span style=display:flex><span><span style=color:#5af78e>EOF</span>
</span></span><span style=display:flex><span>kubectl get pods -A
</span></span></code></pre></td></tr></table></div></div><p>您可以看到dcgmproftester Pod正在运行，然后是Grafana仪表板上显示的指标。GPU利用率（GrActive）已达到98%的峰值。您还可能会发现其他指标很有趣，例如功率或GPU内存。</p><p>DCGM最近添加了一些设备级指标。其中包括细粒度的GPU利用率指标，可以监控SM占用率和张量核利用率。有关更多信息，请参阅《DCGM用户指南》中的评测指标。为了方便起见，当您使用Helm Charts部署dcgm-exporter时，默认情况下会将其配置为收集这些指标。</p><p>DCGM API文档中提供了GPU指标。通过使用GPU指标作为自定义指标和Prometheus Adapter，您可以使用Horizontal Pod Autoscaler根据GPU利用率或其他指标缩放 Pod 数量。</p><h1 id=gtx-与-rtx-系列的-gpu>GTX 与 RTX 系列的 GPU</h1><p>不幸的是，只有分析指标仅限于数据中心（以前的“Tesla”）品牌 GPU，例如 A100、V100 和 T4。但是，您仍然可以使用 dcgm-exporter 来访问 GTX 和 RTX 系列上的其他 GPU 遥测。为此，您必须在安装过程中覆盖 Helm 图表中的“arguments”变量并将其设置为 nil。例如，您可以直接在Helm图表中修改values.yaml。</p><div class=highlight><div style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>helm install --generate-name gpu-helm-charts/dcgm-exporter --set <span style=color:#ff5c57>arguments</span><span style=color:#ff6ac1>=</span>null
</span></span></code></pre></td></tr></table></div></div><p>这样做将允许 dcgm-exporter 为您提供所有 GPU 遥测数据（只是不是分析指标），并且不会在启动过程中导致错误。</p><h1 id=二次开发>二次开发</h1><p>NVIDIA 并不像 AMD 那样缺少软件支持，因此你可以通过 Golang 或者 Python 接入自己的监控系统。NVIDIA 提供了 NVML 的 Golang 绑定：<a href=https://github.com/NVIDIA/go-nvml>https://github.com/NVIDIA/go-nvml</a> 和 DCGM 的 Golang 绑定：<a href=https://github.com/NVIDIA/go-dcgm>https://github.com/NVIDIA/go-dcgm</a>。</p><p>此外，Kubernetes 通过 Device Plugin Framework 提供对 NVIDIA GPU、NIC、Infiniband 适配器和其他设备等特殊硬件资源的访问。然而，使用这些硬件资源配置和管理节点需要配置多个软件组件，例如驱动程序、容器运行时或其他库，这些组件很难并且容易出错。NVIDIA GPU Operator 使用Kubernetes中的 Operator Framework 来自动管理提供GPU所需的所有NVIDIA软件组件。这些组件包括NVIDIA驱动程序（用于启用CUDA）、用于GPU的Kubernetes设备插件、NVIDIA容器运行时、自动节点标记、基于DCGM的监控等。GPU Operator 允许 Kubernetes 集群的管理员像管理集群中的 CPU 节点一样管理 GPU 节点。管理员无需为 GPU 节点配置特殊的操作系统映像，而是可以依赖 CPU 和 GPU 节点的标准操作系统映像，然后依靠 GPU Operator 为 GPU 配置所需的软件组件。请注意，GPU Operator 对于 Kubernetes 集群需要快速扩展的场景特别有用，例如在云端或本地配置额外的 GPU 节点以及管理底层软件组件的生命周期。由于 GPU Operator 将所有内容作为容器运行（包括 NVIDIA 驱动程序），因此管理员只需启动或停止容器即可轻松交换各种组件。存储库地址：<a href=https://github.com/NVIDIA/gpu-operator>https://github.com/NVIDIA/gpu-operator</a>。</p></div></div><footer id=footer><div class=footer-inner><div><div style=font-weight:700;margin-bottom:15px>发布地址</div><div><a href=https://halo.wecomz.com>Halo的主页</a></div><div><a href=https://bluemiaomiao.gitee.io>中国境内镜像</a></div><div><a href=https://bluemiaomiao.github.io>中国境外镜像</a></div></div><div><div style=font-weight:700;margin-bottom:15px>友情链接</div><div><a href=https://debuginn.cn>DebugInn</a></div><div><a href=https://blog.csdn.net/qq_43442524>普通Gopher</a></div></div><div><div style=font-weight:700;margin-bottom:15px>开源软件</div><div><a href=https://bluemiaomiao.github.io/libsshd/>OpenSSH Configuration Library</a></div><div><a href=https://bluemiaomiao.github.io/fastdfs-spring-boot-starter/>FastDFS SpringBoot Starter</a></div><div><a href=https://bluemiaomiao.github.io/librocm-smi-gobinding/>AMD ROCm SMI for Golang</a></div><div><a href=https://bluemiaomiao.github.io/libnvml-smi-gobinding>NVIDIA NVML SMI for Golang</a></div><div><a href=https://www.wecomz.com/software/zgraphics>zGraphics(Prometheus GPU Exporter)</a></div><div><a href=https://www.wecomz.com/software/ztrader>zTrader Framework</a></div></div><div><div style=font-weight:700;margin-bottom:15px>其他</div><div><a href=https://values.wecomz.com>WecomZ 价值观</a></div></div></div><div class=icp><div style=min-height:13px;min-width:13px;background-image:url(/image/beian.png);background-repeat:no-repeat;background-size:contain;margin-right:5px></div><div><a href=https://beian.miit.gov.cn target=_blank>鲁ICP备2023019133号</a></div></div></footer></body><script src=../../js/halo.js type=text/javascript></script></html>